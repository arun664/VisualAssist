# AI Navigation Assistant - Architecture Summary

## System Overview

The AI Navigation Assistant provides **continuous visual monitoring** with **optional audio guidance** through a three-component distributed architecture.

## Component Roles

### ğŸ¥ Client Device (Port 3001)
**Role**: Media capture and streaming
- **Media Access**: Camera and microphone permissions required
- **Functionality**: Captures video/audio â†’ Streams via WebRTC to backend
- **User**: Person carrying the mobile device during navigation
- **Interface**: Mobile-optimized with media controls

### ğŸ§  Backend Server (Port 8000)
**Role**: AI processing and coordination
- **Processing**: YOLOv11 object detection + OpenCV optical flow analysis
- **State Management**: Navigation FSM (IDLE â†’ SCANNING â†’ GUIDING â†’ BLOCKED)
- **Streaming**: Serves processed video with AI overlays at `/processed_video_stream`
- **Communication**: WebSocket for commands, HTTP for WebRTC offers

### ğŸ–¥ï¸ Frontend Interface (Port 3000)
**Role**: Monitoring dashboard with optional guidance
- **Media Access**: NO camera/microphone permissions needed
- **Always Available**: Processed video stream with AI overlays
- **Optional**: Audio guidance when "Start Navigation" is activated
- **User**: Operators, supervisors, or monitoring personnel

## Operating Modes

### ğŸ“Š Monitoring Mode (Default State)
```
Client â†’ Backend â†’ Frontend
  ğŸ“¹        ğŸ§         ğŸ‘ï¸
Video    Process   Display
Audio   Analyze    Monitor
        Detect     (Silent)
```

**Behavior**:
- âœ… Processed video stream always visible
- âœ… Real-time AI overlays and object detection
- âœ… FSM state changes displayed
- âœ… Visual status updates
- âŒ Audio guidance muted

**Use Cases**:
- System monitoring and supervision
- Visual analysis of AI processing
- Training and demonstration
- Remote observation

### ğŸ¯ Navigation Mode (User-Activated)
```
Client â†’ Backend â†’ Frontend
  ğŸ“¹        ğŸ§         ğŸ‘ï¸ğŸ”Š
Video    Process   Display
Audio   Analyze    Monitor
        Detect     + Guide
        Generate   + Speak
```

**Behavior**:
- âœ… Same visual monitoring as above
- âœ… PLUS audio guidance activated
- âœ… Voice instructions: "Path clear", "Obstacle detected"
- âœ… Emergency alerts: "STOP! Danger ahead"
- âœ… Urgency-based audio priority

**Use Cases**:
- Active navigation assistance
- Real-time guidance with audio feedback
- Emergency obstacle warnings
- Complete navigation experience

## Data Flow

### Continuous Monitoring Flow
1. **Client** captures camera feed
2. **Backend** processes with YOLOv11 + OpenCV
3. **Backend** serves processed video at `/processed_video_stream`
4. **Frontend** displays processed video automatically
5. **Visual feedback** shows detections and states

### Navigation Guidance Flow (Additional)
1. **Backend** generates navigation messages based on AI analysis
2. **Backend** sends messages via WebSocket to frontend
3. **Frontend** checks if navigation is active
4. **If active**: Plays audio guidance + shows visual alerts
5. **If monitoring**: Shows visual feedback only (audio muted)

## Key Benefits

### ğŸ”„ Always-On Monitoring
- Processed video stream available 24/7
- Real-time AI analysis visible
- System status continuously updated
- No interruption when switching modes

### ğŸ›ï¸ Selective Audio Control
- Audio guidance only when needed
- Prevents audio fatigue during monitoring
- Allows silent observation
- Emergency alerts still prioritized

### ğŸ‘¥ Multi-User Support
- **Operators** can monitor without audio
- **Navigation users** get full audio guidance
- **Supervisors** can observe system behavior
- **Developers** can debug with visual feedback

### ğŸš¨ Safety First
- Visual alerts always visible
- Emergency audio overrides mute state
- Continuous monitoring ensures safety
- Redundant feedback channels

## Technical Implementation

### Frontend State Management
```javascript
class NavigationApp {
    isNavigating: false           // Controls audio guidance
    videoController.connectToStream()  // Always active for monitoring
    handleAudioMessage(text) {
        showVisualFeedback(text)  // Always
        if (isNavigating) {
            audioSystem.speak(text) // Only when navigating
        }
    }
}
```

### Backend Processing
```python
# Always processes video and generates messages
# Frontend decides whether to play audio based on navigation state
```

This architecture provides the perfect balance of **continuous monitoring** with **selective guidance**, ensuring safety while preventing audio fatigue.