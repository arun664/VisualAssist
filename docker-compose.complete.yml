version: '3.8'

services:
  ai-navigation-complete:
    build:
      context: .
      dockerfile: Dockerfile
    image: ai-navigation-complete:latest
    container_name: ai-navigation-complete
    ports:
      - "80:80"      # Frontend (Nginx)
      - "8000:8000"  # Backend API (direct access)
    environment:
      - ENVIRONMENT=production
      - SERVER_HOST=127.0.0.1
      - SERVER_PORT=8000
      - FRONTEND_PORT=80
      - PYTHONPATH=/app/backend
      - YOLO_CONFIG_DIR=/app/backend/models
      - NUMBA_CACHE_DIR=/tmp/numba_cache
    volumes:
      # Persistent storage for logs and models
      - ./backend/logs:/app/backend/logs
      - ./backend/models:/app/backend/models
      # Optional: Custom nginx config
      # - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health", "||", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 90s
    networks:
      - ai-navigation-network

  # Development version with different ports
  ai-navigation-dev:
    build:
      context: .
      dockerfile: Dockerfile
    image: ai-navigation-complete:dev
    container_name: ai-navigation-dev
    ports:
      - "3000:80"    # Frontend on port 3000
      - "8001:8000"  # Backend on port 8001
    environment:
      - ENVIRONMENT=development
      - SERVER_HOST=127.0.0.1
      - SERVER_PORT=8000
      - FRONTEND_PORT=80
      - PYTHONPATH=/app/backend
    volumes:
      - ./backend/logs:/app/backend/logs
      - ./backend/models:/app/backend/models
      # Development: Mount source code for live editing
      - ./client:/app/client:ro
      - ./backend:/app/backend:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - ai-navigation-network
    profiles:
      - dev  # Only start with --profile dev

  # Load balancer for multiple instances
  nginx-lb:
    image: nginx:alpine
    container_name: ai-navigation-lb
    ports:
      - "443:443"
      - "8080:80"
    volumes:
      - ./docker/nginx-lb.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - ai-navigation-complete
    networks:
      - ai-navigation-network
    profiles:
      - production  # Only start with --profile production

  # Monitoring with Prometheus (optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-navigation-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - ai-navigation-network
    profiles:
      - monitoring  # Only start with --profile monitoring

  # Grafana for visualization (optional)
  grafana:
    image: grafana/grafana:latest
    container_name: ai-navigation-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./docker/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - ai-navigation-network
    profiles:
      - monitoring  # Only start with --profile monitoring

networks:
  ai-navigation-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  prometheus_data:
  grafana_data:

# Usage Examples:
#
# Basic usage (production):
#   docker-compose -f docker-compose.complete.yml up
#
# Development mode:
#   docker-compose -f docker-compose.complete.yml --profile dev up
#
# Production with load balancer:
#   docker-compose -f docker-compose.complete.yml --profile production up
#
# With monitoring:
#   docker-compose -f docker-compose.complete.yml --profile monitoring up
#
# All services:
#   docker-compose -f docker-compose.complete.yml --profile dev --profile production --profile monitoring up